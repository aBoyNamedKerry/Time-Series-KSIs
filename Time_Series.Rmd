---
title: "Time Series in R with KSI collisions"
author: "Kerry Cella"
date: "2 August 2016"
output: 
    html_document:
        toc: yes
        toc_depth: 4
---
<br>
<br>

#### 1. Introduction

This document covers some of R's functions for looking at time series data. It includes:

- Connecting to the TfL API as shown here: <https://rawgit.com/maczokni/rest-api-through-firewall/gh-pages/tutorial.html>

- Using the dplyr package

- How to read in multiple years from the API

- Using the 'date' format in R

- creating a time series object ts

- forecasting from this object.

We need the following packages. If you don't have them use the install.packages() function first to download them from CRAN.

```{r, warning= F, message=F}
library(dygraphs); library(jsonlite); library(dplyr);library(zoo); library(forecast)
```
<br>

#### 2. Data

We're going to connect to the TfL API again and extract collision data. As per last week we need to create object for our ID, Key and year we want. 

Because we are interested in seeing the shape of collisiona over time we're going to need more than one year. We therefore create a list object **d_list** and the run a for loop to call three years from 2013 to 2015 from the api.

```{r, warning = FALSE, message=FALSE, eval= FALSE}
myAppId <- "your ID"
myAppKey <- "your app key"

d_list<- list()

#we create a loop to call data from multiple years from the API
for (i in c("2013","2014","2015")){

  requestUrl <- paste0("https://api.tfl.gov.uk/AccidentStats/",
                       i, "?app_id=", myAppId, "&app_key=", myAppKey)


 l = readLines(requestUrl, encoding="UTF-8", warn=FALSE)
 d = fromJSON(l)
  
 d_list[[i]] <- d
}
```


```{r, warning = FALSE, message=FALSE, echo = FALSE}
myAppId <- "786fe686"
myAppKey <- "66de5306c2b994332134fbef098680d7"

d_list<- list()

#we create a loop to call data from multiple years from the API
for (i in c("2013","2014","2015")){

  requestUrl <- paste0("https://api.tfl.gov.uk/AccidentStats/",
                       i, "?app_id=", myAppId, "&app_key=", myAppKey)


 l = readLines(requestUrl, encoding="UTF-8", warn=FALSE)
 d = fromJSON(l)
  
 d_list[[i]] <- d
}
```

We then collapse the listed objects into a single data frame. Luckily the dplyr package has a function to do this.

```{r}
 d<- rbind_all(d_list)
```

If we now type `View(d)` we should see the data frame.

We have some columns we don't need for now such as the casualty list. We also note that the date is in an oddly concatenated character string. Let's remove the columns we're not interested in using the select() function in dplyr and then get the date  into a format we can use.The substr() function takes the positions in the string we want to take counting from the right.

```{r}
 d_clean<-d%>% select(id, lat,lon, location, dateandTime=date, severity, borough)

d_clean$date<-substr(d_clean$date,1,10)

head(d_clean$date)
```

R won't recognise our date field automatically so we need to tell it it's a date. This requires the as.Date() function. If we query by executing `?strptime` it gives us a list of the characters and paramaters we need to use. We check the class before and after as a demonstration.


```{r}

class(d_clean$date)

d_clean$date<-as.Date(d_clean$date, "%Y-%m-%d")

class(d_clean$date)

```

For our time series we are going to group the data by month and year. R is a little bit fiddly with sorting date data. We first need to create a new year and month column.

```{r}
d_clean$yearMonth<-format(d_clean$date, "%Y-%m")

class(d_clean$yearMonth)
```

You'll notice it's reverted back into a character vector so let's use the zoo package to tell R we want a Year and month column as a date. It will place a 01 day suffix to do this.

```{r}

d_clean$yearMonth<-as.Date(as.yearmon(d_clean$yearMonth))


class(d_clean$yearMonth)
```

It's also reverted back to a date - which is good.

OK for now we're going to concentrate on looking at collisions which resulted in a killed or serious injury (KSI). We need to extract those that resulted in a fatal or serious injury. There are three ways of doing this, we can use the subset() function, or subset through indexing from the data frame, data[x == "",] however we're going to use the filter() function from the dplyr and create a new variable `d_clean_KSI`.

```{r}
d_clean_KSI<- d_clean%>% filter(severity == "Serious" | severity == "Fatal")
```


We can now use the table function to group the number of KSI collisions per month:

```{r}
table(d_clean_KSI$yearMonth)
```
<br>

#### 3. Time Series

To create the time series we just need the vector of values per month, so we'll extract this and make a new object called ksi_cols.

```{r}
ksi_cols<-as.vector(table(d_clean_KSI$yearMonth))
```

Now let's create a time series object in R, ts(). We need to specify our start and end dates and also the frequency of intervals. If you put 12, the object should automatically assume you are working in months.

```{r}
ksi_ts<-ts(data =ksi_cols, start = c(2013,1) , end =c(2015,12), frequency= 12)
```


Now we can use the plot function in R to make a nice and quick basic plot.

```{r}
plot(ksi_ts, col = "blue", lwd =2, ylab = "KSI", 
        main = "Collisions resulting in KSI 2013-2015")
grid()
```

Or if we're feeling a bit fancy we can also build in a html widget using the dygraphs package for a bit more interactivity. Plus it fixes the odd x axis labelling.

```{r}
dygraph(ksi_ts)
```

It looks like there might be some trend in the data but it's hard to see through the noise. To check we can use a function in R called decompose() which will pull the time series into it components parts. We then use the plot function to see what this looks like.

```{r}
ksi_decomp<- decompose(ksi_ts)
plot(ksi_decomp)
```

The plot is divided into four parts, the observed data, a moving average trend, a seasonal component and the random element. You'll notice the model has defaulted to **Additive**. This basically means we expect the seasonaility to remain constant with the trend. The alternative would be to use a **Multiplicative** model where seasonaility increases with trend. This can be  specified through `decompose(x, type = "multiplicative")`. I would say this data is a good candidate for using the multiplicative model decomposition instead but we will stick to additive for this example.

There appears to be seasonality in the data. We can check the seasonal components as follows.

``` {r}
ksi_decomp$seasonal
```

We can see October consistently spikes each year. Therefore this might be a time where we want to or do focus our enforcement or road campaign activity.

As a quick aside, there is an alternative to using the decompose() function which some people recommend called stl(). The stl function uses a loess smoother to decompose the data and you can find more information about it through ?stl. There is also a paper found here <http://cs.wellesley.edu/~cs315/Papers/stl%20statistical%20model.pdf>

OK back to our data. We know there is trend and seasonality in the data, and the trend is downwards (yay). However if we are going to start forecasting with it we also want to know whether there is any autocorrelation, bascially does the value of one observation affect the next one sequentially.

We can check auto-correlation from the 'forecast' package. We can use both a Box-Pierce test and also use an Acf() function to plot the data and test this.

```{r}
Box.test(ksi_ts)

Acf(ksi_ts)
```

We see no evidence of autocorrelation in either result. The test is non-significant so we fail to reject the null hypothesis that observation are independent. This is confiremd by the plot not showing any auto-correlation in the lags (with the exception of one that looks like a chance observation).

<br>

#### 4. Forecasting

OK let's finish with some basic forecasting. The 'forecast' package has a range of different tools we can use for this. I'm going to cover a basicset of four.

First let's base our forecast on the **mean** of the data. That's right we're just going to take look at what the average is to predict the next six months.

```{r}
meanf(ksi_ts, h =6)
```

You'll notice you'll get the same prediction for the next six months with confidence intervals. This is the similar to as using a standard control chart. The problem with the mean of course is it fail to address either trend or seasonality in the data.

OK next, we'll use the **naive forecast** taking just the last observed value.

```{r}
snaive(ksi_ts, h =6)
```

This might be slightly better in some circumstances but again ignores trend and seasonality.

Next is the **seasonally naive** forecast.

```{r}
snaive(ksi_ts, h =6)
```

OK so this looks at last years date and at least take into account the seasonality, but we still arguably have a trend issue.

The last is the **drift forecast** method, which takes the last observed value plus the average change seen. 

```{r}
rwf(ksi_ts, drift = T, h =6)
```

This at least takes the trend of the data into account. Under our assumption of diminshing seasonality, seasonality may be less important and therefore fit within the confidence intervals.  

That's it, for those who are interested these techniques are explained in a lot more detail here by the chap who wrote the forecast package! <http://robjhyndman.com/talks/MelbourneRUG.pdf>

Finally an alternative and recommended package for manipulating date data is the lubridate package by Hadley Wickham (of course). For more information on this check <https://cran.r-project.org/web/packages/lubridate/lubridate.pdf>

I hope this was useful.

